{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Ionosphere Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1fBNsZf70OM"
      },
      "source": [
        "# Assignment: Ionosphere Data Problem\n",
        "\n",
        "### Dataset Description: \n",
        "\n",
        "This radar data was collected by a system in Goose Bay, Labrador. This system consists of a phased array of 16 high-frequency antennas with a total transmitted power on the order of 6.4 kilowatts. See the paper for more details. The targets were free electrons in the ionosphere. \"Good\" radar returns are those showing evidence of some type of structure in the ionosphere. \"Bad\" returns are those that do not; their signals pass through the ionosphere.\n",
        "\n",
        "Received signals were processed using an autocorrelation function whose arguments are the time of a pulse and the pulse number. There were 17 pulse numbers for the Goose Bay system. Instances in this databse are described by 2 attributes per pulse number, corresponding to the complex values returned by the function resulting from the complex electromagnetic signal.\n",
        "\n",
        "### Attribute Information:\n",
        "\n",
        "- All 34 are continuous\n",
        "- The 35th attribute is either \"good\" or \"bad\" according to the definition summarized above. This is a binary classification task.\n",
        "\n",
        " <br><br>\n",
        "\n",
        "<table border=\"1\"  cellpadding=\"6\">\n",
        "\t<tbody>\n",
        "        <tr>\n",
        "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Data Set Characteristics:&nbsp;&nbsp;</b></p></td>\n",
        "\t\t<td><p class=\"normal\">Multivariate</p></td>\n",
        "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Instances:</b></p></td>\n",
        "\t\t<td><p class=\"normal\">351</p></td>\n",
        "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Area:</b></p></td>\n",
        "\t\t<td><p class=\"normal\">Physical</p></td>\n",
        "        </tr>\n",
        "     </tbody>\n",
        "    </table>\n",
        "<table border=\"1\" cellpadding=\"6\">\n",
        "    <tbody>\n",
        "        <tr>\n",
        "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Attribute Characteristics:</b></p></td>\n",
        "            <td><p class=\"normal\">Integer,Real</p></td>\n",
        "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Attributes:</b></p></td>\n",
        "            <td><p class=\"normal\">34</p></td>\n",
        "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Date Donated</b></p></td>\n",
        "            <td><p class=\"normal\">N/A</p></td>\n",
        "        </tr>\n",
        "     </tbody>\n",
        "    </table>\n",
        "<table border=\"1\" cellpadding=\"6\">\t\n",
        "    <tbody>\n",
        "    <tr>\n",
        "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Associated Tasks:</b></p></td>\n",
        "\t\t<td><p class=\"normal\">Classification</p></td>\n",
        "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Missing Values?</b></p></td>\n",
        "\t\t<td><p class=\"normal\">N/A</p></td>\n",
        "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Web Hits:</b></p></td>\n",
        "\t\t<td><p class=\"normal\">N/A</p></td>\n",
        "\t</tr>\n",
        "    </tbody>\n",
        "    </table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcDvS5Ya70OW"
      },
      "source": [
        "### WORKFLOW :\n",
        "- Load Data\n",
        "- Check Missing Values ( If Exist ; Fill each record with mean of its feature ) or any usless column.\n",
        "- Shuffle the data if needed.\n",
        "- Standardized the Input Variables. **Hint**: Centeralized the data\n",
        "- Split into 60 and 40 ratio.\n",
        "- Encode labels.\n",
        "- Model : 1 hidden layers including 16 unit.\n",
        "- Compilation Step (Note : Its a Binary problem , select loss , metrics according to it)\n",
        "- Train the Model with Epochs (100).\n",
        "- If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .\n",
        "- Prediction should be > **92%**\n",
        "- Evaluation Step\n",
        "- Prediction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwT7Woyi70OX"
      },
      "source": [
        "# Load Data:\n",
        "[Click Here to Download DataSet](https://github.com/ramsha275/ML_Datasets/blob/main/ionosphere_data.csv)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwBqStJG8pm8"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam, SGD"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXp7wlKn8s7b",
        "outputId": "35eade8d-c235-42ce-c213-db3dbe375ce1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZL0JADD8t8B"
      },
      "source": [
        "data = pd.read_csv('/content/gdrive/MyDrive/ionosphere_data.csv')"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ic0-o14F9rf6",
        "outputId": "e2cdace9-fa1e-44e6-81a2-39272a33e9c4"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(351, 35)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "u5kp73Bb9tOn",
        "outputId": "9720a375-cb69-4b04-b2f0-8073dc60592e"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature1</th>\n",
              "      <th>feature2</th>\n",
              "      <th>feature3</th>\n",
              "      <th>feature4</th>\n",
              "      <th>feature5</th>\n",
              "      <th>feature6</th>\n",
              "      <th>feature7</th>\n",
              "      <th>feature8</th>\n",
              "      <th>feature9</th>\n",
              "      <th>feature10</th>\n",
              "      <th>feature11</th>\n",
              "      <th>feature12</th>\n",
              "      <th>feature13</th>\n",
              "      <th>feature14</th>\n",
              "      <th>feature15</th>\n",
              "      <th>feature16</th>\n",
              "      <th>feature17</th>\n",
              "      <th>feature18</th>\n",
              "      <th>feature19</th>\n",
              "      <th>feature20</th>\n",
              "      <th>feature21</th>\n",
              "      <th>feature22</th>\n",
              "      <th>feature23</th>\n",
              "      <th>feature24</th>\n",
              "      <th>feature25</th>\n",
              "      <th>feature26</th>\n",
              "      <th>feature27</th>\n",
              "      <th>feature28</th>\n",
              "      <th>feature29</th>\n",
              "      <th>feature30</th>\n",
              "      <th>feature31</th>\n",
              "      <th>feature32</th>\n",
              "      <th>feature33</th>\n",
              "      <th>feature34</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.99539</td>\n",
              "      <td>-0.05889</td>\n",
              "      <td>0.85243</td>\n",
              "      <td>0.02306</td>\n",
              "      <td>0.83398</td>\n",
              "      <td>-0.37708</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.03760</td>\n",
              "      <td>0.85243</td>\n",
              "      <td>-0.17755</td>\n",
              "      <td>0.59755</td>\n",
              "      <td>-0.44945</td>\n",
              "      <td>0.60536</td>\n",
              "      <td>-0.38223</td>\n",
              "      <td>0.84356</td>\n",
              "      <td>-0.38542</td>\n",
              "      <td>0.58212</td>\n",
              "      <td>-0.32192</td>\n",
              "      <td>0.56971</td>\n",
              "      <td>-0.29674</td>\n",
              "      <td>0.36946</td>\n",
              "      <td>-0.47357</td>\n",
              "      <td>0.56811</td>\n",
              "      <td>-0.51171</td>\n",
              "      <td>0.41078</td>\n",
              "      <td>-0.46168</td>\n",
              "      <td>0.21266</td>\n",
              "      <td>-0.34090</td>\n",
              "      <td>0.42267</td>\n",
              "      <td>-0.54487</td>\n",
              "      <td>0.18641</td>\n",
              "      <td>-0.45300</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.18829</td>\n",
              "      <td>0.93035</td>\n",
              "      <td>-0.36156</td>\n",
              "      <td>-0.10868</td>\n",
              "      <td>-0.93597</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.04549</td>\n",
              "      <td>0.50874</td>\n",
              "      <td>-0.67743</td>\n",
              "      <td>0.34432</td>\n",
              "      <td>-0.69707</td>\n",
              "      <td>-0.51685</td>\n",
              "      <td>-0.97515</td>\n",
              "      <td>0.05499</td>\n",
              "      <td>-0.62237</td>\n",
              "      <td>0.33109</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-0.13151</td>\n",
              "      <td>-0.45300</td>\n",
              "      <td>-0.18056</td>\n",
              "      <td>-0.35734</td>\n",
              "      <td>-0.20332</td>\n",
              "      <td>-0.26569</td>\n",
              "      <td>-0.20468</td>\n",
              "      <td>-0.18401</td>\n",
              "      <td>-0.19040</td>\n",
              "      <td>-0.11593</td>\n",
              "      <td>-0.16626</td>\n",
              "      <td>-0.06288</td>\n",
              "      <td>-0.13738</td>\n",
              "      <td>-0.02447</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.03365</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.00485</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.12062</td>\n",
              "      <td>0.88965</td>\n",
              "      <td>0.01198</td>\n",
              "      <td>0.73082</td>\n",
              "      <td>0.05346</td>\n",
              "      <td>0.85443</td>\n",
              "      <td>0.00827</td>\n",
              "      <td>0.54591</td>\n",
              "      <td>0.00299</td>\n",
              "      <td>0.83775</td>\n",
              "      <td>-0.13644</td>\n",
              "      <td>0.75535</td>\n",
              "      <td>-0.08540</td>\n",
              "      <td>0.70887</td>\n",
              "      <td>-0.27502</td>\n",
              "      <td>0.43385</td>\n",
              "      <td>-0.12062</td>\n",
              "      <td>0.57528</td>\n",
              "      <td>-0.40220</td>\n",
              "      <td>0.58984</td>\n",
              "      <td>-0.22145</td>\n",
              "      <td>0.43100</td>\n",
              "      <td>-0.17365</td>\n",
              "      <td>0.60436</td>\n",
              "      <td>-0.24180</td>\n",
              "      <td>0.56045</td>\n",
              "      <td>-0.38238</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.45161</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.71216</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>0.14516</td>\n",
              "      <td>0.54094</td>\n",
              "      <td>-0.39330</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-0.54467</td>\n",
              "      <td>-0.69975</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.90695</td>\n",
              "      <td>0.51613</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.20099</td>\n",
              "      <td>0.25682</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.32382</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.02401</td>\n",
              "      <td>0.94140</td>\n",
              "      <td>0.06531</td>\n",
              "      <td>0.92106</td>\n",
              "      <td>-0.23255</td>\n",
              "      <td>0.77152</td>\n",
              "      <td>-0.16399</td>\n",
              "      <td>0.52798</td>\n",
              "      <td>-0.20275</td>\n",
              "      <td>0.56409</td>\n",
              "      <td>-0.00712</td>\n",
              "      <td>0.34395</td>\n",
              "      <td>-0.27457</td>\n",
              "      <td>0.52940</td>\n",
              "      <td>-0.21780</td>\n",
              "      <td>0.45107</td>\n",
              "      <td>-0.17813</td>\n",
              "      <td>0.05982</td>\n",
              "      <td>-0.35575</td>\n",
              "      <td>0.02309</td>\n",
              "      <td>-0.52879</td>\n",
              "      <td>0.03286</td>\n",
              "      <td>-0.65158</td>\n",
              "      <td>0.13290</td>\n",
              "      <td>-0.53206</td>\n",
              "      <td>0.02431</td>\n",
              "      <td>-0.62197</td>\n",
              "      <td>-0.05707</td>\n",
              "      <td>-0.59573</td>\n",
              "      <td>-0.04608</td>\n",
              "      <td>-0.65697</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   feature1  feature2  feature3  ...  feature33  feature34  label\n",
              "0         1         0   0.99539  ...    0.18641   -0.45300      g\n",
              "1         1         0   1.00000  ...   -0.13738   -0.02447      b\n",
              "2         1         0   1.00000  ...    0.56045   -0.38238      g\n",
              "3         1         0   1.00000  ...   -0.32382    1.00000      b\n",
              "4         1         0   1.00000  ...   -0.04608   -0.65697      g\n",
              "\n",
              "[5 rows x 35 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WZ4B8r0-H5Q"
      },
      "source": [
        "#### Checking Missing Valoues"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUFJsDOL-Aae",
        "outputId": "44475c31-d592-461c-b264-e3fcd3d2b8f2"
      },
      "source": [
        "data.isnull().sum()"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "feature1     0\n",
              "feature2     0\n",
              "feature3     0\n",
              "feature4     0\n",
              "feature5     0\n",
              "feature6     0\n",
              "feature7     0\n",
              "feature8     0\n",
              "feature9     0\n",
              "feature10    0\n",
              "feature11    0\n",
              "feature12    0\n",
              "feature13    0\n",
              "feature14    0\n",
              "feature15    0\n",
              "feature16    0\n",
              "feature17    0\n",
              "feature18    0\n",
              "feature19    0\n",
              "feature20    0\n",
              "feature21    0\n",
              "feature22    0\n",
              "feature23    0\n",
              "feature24    0\n",
              "feature25    0\n",
              "feature26    0\n",
              "feature27    0\n",
              "feature28    0\n",
              "feature29    0\n",
              "feature30    0\n",
              "feature31    0\n",
              "feature32    0\n",
              "feature33    0\n",
              "feature34    0\n",
              "label        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70rt7vaM-SEN",
        "outputId": "3641b481-7285-456c-8626-ab12ee03ac7d"
      },
      "source": [
        "data.info"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.info of      feature1  feature2  feature3  ...  feature33  feature34  label\n",
              "0           1         0   0.99539  ...    0.18641   -0.45300      g\n",
              "1           1         0   1.00000  ...   -0.13738   -0.02447      b\n",
              "2           1         0   1.00000  ...    0.56045   -0.38238      g\n",
              "3           1         0   1.00000  ...   -0.32382    1.00000      b\n",
              "4           1         0   1.00000  ...   -0.04608   -0.65697      g\n",
              "..        ...       ...       ...  ...        ...        ...    ...\n",
              "346         1         0   0.83508  ...    0.90546   -0.04307      g\n",
              "347         1         0   0.95113  ...    0.91483    0.04712      g\n",
              "348         1         0   0.94701  ...    0.92697   -0.00577      g\n",
              "349         1         0   0.90608  ...    0.87403   -0.16243      g\n",
              "350         1         0   0.84710  ...    0.85764   -0.06151      g\n",
              "\n",
              "[351 rows x 35 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERWh6pP2A5SJ"
      },
      "source": [
        "### Data Shuffling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxHnJb0SAqWJ"
      },
      "source": [
        "data = data.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdSR2rPGV5TM"
      },
      "source": [
        "### Label Encoding "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDMOrlwPWeVZ"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder = LabelEncoder()\n",
        "data['feature1']=labelencoder.fit_transform(data['feature1'])\n",
        "data['feature2']=labelencoder.fit_transform(data['feature2'])\n",
        "data['feature3']=labelencoder.fit_transform(data['feature3'])\n",
        "data['feature4']=labelencoder.fit_transform(data['feature4'])\n",
        "data['feature5']=labelencoder.fit_transform(data['feature5'])\n",
        "data['feature6']=labelencoder.fit_transform(data['feature6'])\n",
        "data['feature7']=labelencoder.fit_transform(data['feature7'])\n",
        "data['feature8']=labelencoder.fit_transform(data['feature8'])\n",
        "data['feature9']=labelencoder.fit_transform(data['feature9'])\n",
        "data['feature10']=labelencoder.fit_transform(data['feature10'])\n",
        "data['feature11']=labelencoder.fit_transform(data['feature11'])\n",
        "data['feature12']=labelencoder.fit_transform(data['feature12'])\n",
        "data['feature13']=labelencoder.fit_transform(data['feature13'])\n",
        "data['feature14']=labelencoder.fit_transform(data['feature14'])\n",
        "data['feature15']=labelencoder.fit_transform(data['feature15'])\n",
        "data['feature16']=labelencoder.fit_transform(data['feature16'])\n",
        "data['feature17']=labelencoder.fit_transform(data['feature17'])\n",
        "data['feature18']=labelencoder.fit_transform(data['feature18'])\n",
        "data['feature19']=labelencoder.fit_transform(data['feature19'])\n",
        "data['feature20']=labelencoder.fit_transform(data['feature20'])\n",
        "data['feature21']=labelencoder.fit_transform(data['feature21'])\n",
        "data['feature22']=labelencoder.fit_transform(data['feature22'])\n",
        "data['feature23']=labelencoder.fit_transform(data['feature23'])\n",
        "data['feature24']=labelencoder.fit_transform(data['feature24'])\n",
        "data['feature25']=labelencoder.fit_transform(data['feature25'])\n",
        "data['feature26']=labelencoder.fit_transform(data['feature26'])\n",
        "data['feature27']=labelencoder.fit_transform(data['feature27'])\n",
        "data['feature28']=labelencoder.fit_transform(data['feature28'])\n",
        "data['feature29']=labelencoder.fit_transform(data['feature29'])\n",
        "data['feature30']=labelencoder.fit_transform(data['feature30'])\n",
        "data['feature31']=labelencoder.fit_transform(data['feature31'])\n",
        "data['feature32']=labelencoder.fit_transform(data['feature32'])\n",
        "data['feature33']=labelencoder.fit_transform(data['feature33'])\n",
        "data['feature34']=labelencoder.fit_transform(data['feature34'])\n",
        "\n",
        "\n"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5pZaeU5V4C8"
      },
      "source": [
        "data['label'] = data['label'].map({'g':1,'b':0})"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "zYEklu_SA6LD",
        "outputId": "839a51f6-e967-40ef-c591-7944b21b5d58"
      },
      "source": [
        "data.tail()"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature1</th>\n",
              "      <th>feature2</th>\n",
              "      <th>feature3</th>\n",
              "      <th>feature4</th>\n",
              "      <th>feature5</th>\n",
              "      <th>feature6</th>\n",
              "      <th>feature7</th>\n",
              "      <th>feature8</th>\n",
              "      <th>feature9</th>\n",
              "      <th>feature10</th>\n",
              "      <th>feature11</th>\n",
              "      <th>feature12</th>\n",
              "      <th>feature13</th>\n",
              "      <th>feature14</th>\n",
              "      <th>feature15</th>\n",
              "      <th>feature16</th>\n",
              "      <th>feature17</th>\n",
              "      <th>feature18</th>\n",
              "      <th>feature19</th>\n",
              "      <th>feature20</th>\n",
              "      <th>feature21</th>\n",
              "      <th>feature22</th>\n",
              "      <th>feature23</th>\n",
              "      <th>feature24</th>\n",
              "      <th>feature25</th>\n",
              "      <th>feature26</th>\n",
              "      <th>feature27</th>\n",
              "      <th>feature28</th>\n",
              "      <th>feature29</th>\n",
              "      <th>feature30</th>\n",
              "      <th>feature31</th>\n",
              "      <th>feature32</th>\n",
              "      <th>feature33</th>\n",
              "      <th>feature34</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>95</td>\n",
              "      <td>267</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>54</td>\n",
              "      <td>38</td>\n",
              "      <td>86</td>\n",
              "      <td>26</td>\n",
              "      <td>10</td>\n",
              "      <td>164</td>\n",
              "      <td>88</td>\n",
              "      <td>97</td>\n",
              "      <td>85</td>\n",
              "      <td>73</td>\n",
              "      <td>41</td>\n",
              "      <td>242</td>\n",
              "      <td>81</td>\n",
              "      <td>156</td>\n",
              "      <td>113</td>\n",
              "      <td>156</td>\n",
              "      <td>86</td>\n",
              "      <td>72</td>\n",
              "      <td>18</td>\n",
              "      <td>108</td>\n",
              "      <td>74</td>\n",
              "      <td>40</td>\n",
              "      <td>243</td>\n",
              "      <td>140</td>\n",
              "      <td>7</td>\n",
              "      <td>119</td>\n",
              "      <td>92</td>\n",
              "      <td>152</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>259</td>\n",
              "      <td>243</td>\n",
              "      <td>260</td>\n",
              "      <td>152</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>54</td>\n",
              "      <td>269</td>\n",
              "      <td>114</td>\n",
              "      <td>237</td>\n",
              "      <td>90</td>\n",
              "      <td>55</td>\n",
              "      <td>56</td>\n",
              "      <td>73</td>\n",
              "      <td>57</td>\n",
              "      <td>169</td>\n",
              "      <td>64</td>\n",
              "      <td>180</td>\n",
              "      <td>49</td>\n",
              "      <td>143</td>\n",
              "      <td>40</td>\n",
              "      <td>130</td>\n",
              "      <td>46</td>\n",
              "      <td>143</td>\n",
              "      <td>57</td>\n",
              "      <td>141</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>348</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>218</td>\n",
              "      <td>0</td>\n",
              "      <td>203</td>\n",
              "      <td>258</td>\n",
              "      <td>230</td>\n",
              "      <td>259</td>\n",
              "      <td>243</td>\n",
              "      <td>3</td>\n",
              "      <td>245</td>\n",
              "      <td>268</td>\n",
              "      <td>237</td>\n",
              "      <td>265</td>\n",
              "      <td>233</td>\n",
              "      <td>269</td>\n",
              "      <td>69</td>\n",
              "      <td>140</td>\n",
              "      <td>253</td>\n",
              "      <td>265</td>\n",
              "      <td>247</td>\n",
              "      <td>264</td>\n",
              "      <td>247</td>\n",
              "      <td>0</td>\n",
              "      <td>255</td>\n",
              "      <td>272</td>\n",
              "      <td>255</td>\n",
              "      <td>265</td>\n",
              "      <td>243</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>262</td>\n",
              "      <td>244</td>\n",
              "      <td>262</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>133</td>\n",
              "      <td>234</td>\n",
              "      <td>93</td>\n",
              "      <td>233</td>\n",
              "      <td>60</td>\n",
              "      <td>240</td>\n",
              "      <td>45</td>\n",
              "      <td>239</td>\n",
              "      <td>29</td>\n",
              "      <td>251</td>\n",
              "      <td>27</td>\n",
              "      <td>237</td>\n",
              "      <td>26</td>\n",
              "      <td>219</td>\n",
              "      <td>16</td>\n",
              "      <td>188</td>\n",
              "      <td>16</td>\n",
              "      <td>85</td>\n",
              "      <td>31</td>\n",
              "      <td>43</td>\n",
              "      <td>39</td>\n",
              "      <td>32</td>\n",
              "      <td>53</td>\n",
              "      <td>28</td>\n",
              "      <td>61</td>\n",
              "      <td>36</td>\n",
              "      <td>89</td>\n",
              "      <td>44</td>\n",
              "      <td>129</td>\n",
              "      <td>76</td>\n",
              "      <td>116</td>\n",
              "      <td>148</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>350</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>177</td>\n",
              "      <td>230</td>\n",
              "      <td>105</td>\n",
              "      <td>232</td>\n",
              "      <td>71</td>\n",
              "      <td>246</td>\n",
              "      <td>54</td>\n",
              "      <td>262</td>\n",
              "      <td>31</td>\n",
              "      <td>265</td>\n",
              "      <td>26</td>\n",
              "      <td>252</td>\n",
              "      <td>20</td>\n",
              "      <td>235</td>\n",
              "      <td>3</td>\n",
              "      <td>217</td>\n",
              "      <td>2</td>\n",
              "      <td>107</td>\n",
              "      <td>4</td>\n",
              "      <td>45</td>\n",
              "      <td>15</td>\n",
              "      <td>24</td>\n",
              "      <td>29</td>\n",
              "      <td>7</td>\n",
              "      <td>34</td>\n",
              "      <td>3</td>\n",
              "      <td>83</td>\n",
              "      <td>5</td>\n",
              "      <td>147</td>\n",
              "      <td>17</td>\n",
              "      <td>188</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     feature1  feature2  feature3  ...  feature33  feature34  label\n",
              "346         1         0        95  ...         92        152      0\n",
              "347         1         0        36  ...         57        141      0\n",
              "348         1         0       218  ...        244        262      0\n",
              "349         1         0       133  ...        116        148      1\n",
              "350         1         0       177  ...        188         40      1\n",
              "\n",
              "[5 rows x 35 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nEnY0AQ-gs8"
      },
      "source": [
        "# Separating Input and Output Colmumns \n",
        "X = data.iloc[:, :-1].values  # Input Columns\n",
        "Y = data.iloc[:, -1:].values # Output Columns "
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qiHLCs5-iFY",
        "outputId": "d39a5a44-7c3a-45fb-e299-cf080a625768"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(351, 34)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dULV8QgA-j3I",
        "outputId": "d7ba99ba-bd14-4cc6-a2fb-b3feef8b536a"
      },
      "source": [
        "Y.shape"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(351, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaLMt1kqBtmE"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8pcHnTtANwa"
      },
      "source": [
        ""
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzGeTxrdATCk"
      },
      "source": [
        "### Splitting Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7n8m9gk_-pa"
      },
      "source": [
        "# Total Imagves 351 - Data Split\n",
        "# 351\t60%\t211 Training\n",
        "# 351\t40%\t140 Test\n",
        "\n",
        "x_train = X[:211,] # 60% Training \n",
        "x_test = X[211:351,] # 40% Test \n",
        "\n",
        "\n",
        "y_train = Y[:211,] # 60% Training\n",
        "y_test = Y[211:351,] # 40% Test\n"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBrquLVYC-Ay",
        "outputId": "d2b6d58b-a341-4035-fb80-09e453dbc6cf"
      },
      "source": [
        "print (x_train.shape, x_test.shape)\n",
        "print (y_train.shape, y_test.shape)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(211, 34) (140, 34)\n",
            "(211, 1) (140, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqNDyKINACGW"
      },
      "source": [
        "#### Normalization of Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHQZZqqMzom_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a778eff-c027-45f1-d663-ff921dd11559"
      },
      "source": [
        "x_train = np.asarray(x_train).astype('float32')\n",
        "x_test = np.asarray(x_test).astype('float32')\n",
        "y_train = np.asarray(y_train).astype('float32')\n",
        "y_test = np.asarray(y_test).astype('float32')\n",
        "\n",
        "\n",
        "mean = x_train.mean(axis=0)\n",
        "x_train -= mean\n",
        "\n",
        "std = x_train.std(axis=0)\n",
        "\n",
        "x_test -= mean\n",
        "x_test /= std"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aV_cLKlFb6s"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N82KVeY6FcF0"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers \n",
        "def build_model():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(16, activation='relu', input_shape=(34,)))\n",
        "  model.add(Dense(16, activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  model.compile(optimizer='rmsprop',\n",
        "  loss='binary_crossentropy',\n",
        "  metrics=['acc'])\n",
        "  return model"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BT7Ac6EGdIrh",
        "outputId": "f6d86be8-e9b5-415a-8383-bba2b4b36880"
      },
      "source": [
        "import numpy as np\n",
        "k = 4\n",
        "num_val_samples = len(x_train) // k\n",
        "num_epochs = 50\n",
        "all_scores = []\n",
        "for i in range(k):\n",
        "  print ('processing fold #',i)\n",
        "  val_data = x_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  val_targets = y_train[i *  num_val_samples: (i + 1) * num_val_samples]\n",
        "\n",
        "  partial_train_data = np.concatenate (\n",
        "      [x_train[:i * num_val_samples], \n",
        "       x_train[(i + 1) * num_val_samples:]],\n",
        "       axis=0)\n",
        "  partial_train_targets = np.concatenate(\n",
        "      [y_train[:i * num_val_samples], \n",
        "       y_train[(i + 1) * num_val_samples:]],\n",
        "       axis=0)\n",
        "  model = build_model()\n",
        "  model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size=1, verbose=1)\n",
        "  val_acc, val_loss = model.evaluate(val_data, val_targets, verbose=1)\n",
        "  all_scores.append(val_loss)\n",
        "\n"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "Epoch 1/50\n",
            "159/159 [==============================] - 1s 1ms/step - loss: 14.2561 - acc: 0.4552\n",
            "Epoch 2/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 5.8828 - acc: 0.8040\n",
            "Epoch 3/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 5.3966 - acc: 0.7551\n",
            "Epoch 4/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 2.3532 - acc: 0.8755\n",
            "Epoch 5/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 1.2863 - acc: 0.8625\n",
            "Epoch 6/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.6257 - acc: 0.9063\n",
            "Epoch 7/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.3542 - acc: 0.9387\n",
            "Epoch 8/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.3247 - acc: 0.9368\n",
            "Epoch 9/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.2862 - acc: 0.9300\n",
            "Epoch 10/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.1055 - acc: 0.9768\n",
            "Epoch 11/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0920 - acc: 0.9711\n",
            "Epoch 12/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0115 - acc: 0.9945\n",
            "Epoch 13/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0101 - acc: 0.9959\n",
            "Epoch 14/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0107 - acc: 0.9956\n",
            "Epoch 15/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0094 - acc: 0.9984\n",
            "Epoch 16/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0042 - acc: 1.0000\n",
            "Epoch 17/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0307 - acc: 0.9894\n",
            "Epoch 18/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 8.3333e-04 - acc: 1.0000\n",
            "Epoch 19/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 6.6215e-04 - acc: 1.0000\n",
            "Epoch 20/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0023 - acc: 1.0000\n",
            "Epoch 21/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 2.8708e-04 - acc: 1.0000\n",
            "Epoch 22/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 2.0936e-05 - acc: 1.0000\n",
            "Epoch 23/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 4.9859e-05 - acc: 1.0000\n",
            "Epoch 24/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0014 - acc: 1.0000\n",
            "Epoch 25/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 7.6314e-05 - acc: 1.0000\n",
            "Epoch 26/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0072 - acc: 1.0000\n",
            "Epoch 27/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0026 - acc: 1.0000\n",
            "Epoch 28/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 2.7005e-05 - acc: 1.0000\n",
            "Epoch 29/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 4.3398e-06 - acc: 1.0000\n",
            "Epoch 30/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 8.4267e-05 - acc: 1.0000\n",
            "Epoch 31/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 4.0272e-06 - acc: 1.0000\n",
            "Epoch 32/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 1.6424e-06 - acc: 1.0000\n",
            "Epoch 33/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 9.0811e-07 - acc: 1.0000\n",
            "Epoch 34/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 4.0166e-05 - acc: 1.0000\n",
            "Epoch 35/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 3.1385e-05 - acc: 1.0000\n",
            "Epoch 36/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 5.2216e-06 - acc: 1.0000\n",
            "Epoch 37/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 4.2917e-04 - acc: 0.9996\n",
            "Epoch 38/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 2.3658e-08 - acc: 1.0000\n",
            "Epoch 39/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 4.0062e-06 - acc: 1.0000\n",
            "Epoch 40/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 1.7314e-07 - acc: 1.0000\n",
            "Epoch 41/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 1.7710e-05 - acc: 1.0000\n",
            "Epoch 42/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 6.9346e-07 - acc: 1.0000\n",
            "Epoch 43/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 3.0442e-06 - acc: 1.0000\n",
            "Epoch 44/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 1.0708e-05 - acc: 1.0000\n",
            "Epoch 45/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 4.0241e-05 - acc: 1.0000\n",
            "Epoch 46/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 2.3047e-08 - acc: 1.0000\n",
            "Epoch 47/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 9.4035e-07 - acc: 1.0000\n",
            "Epoch 48/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 1.1248e-05 - acc: 1.0000\n",
            "Epoch 49/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 5.5273e-06 - acc: 1.0000\n",
            "Epoch 50/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 2.5197e-05 - acc: 1.0000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7feb6f42a290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.5253 - acc: 0.8077\n",
            "processing fold # 1\n",
            "Epoch 1/50\n",
            "159/159 [==============================] - 1s 1ms/step - loss: 14.0848 - acc: 0.5956\n",
            "Epoch 2/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 3.8868 - acc: 0.7577\n",
            "Epoch 3/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 1.3004 - acc: 0.7939\n",
            "Epoch 4/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.9844 - acc: 0.8400\n",
            "Epoch 5/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.6962 - acc: 0.8258\n",
            "Epoch 6/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.7323 - acc: 0.8683\n",
            "Epoch 7/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.4937 - acc: 0.9105\n",
            "Epoch 8/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.2506 - acc: 0.9311\n",
            "Epoch 9/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.2247 - acc: 0.9398\n",
            "Epoch 10/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.1234 - acc: 0.9519\n",
            "Epoch 11/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0794 - acc: 0.9656\n",
            "Epoch 12/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0675 - acc: 0.9552\n",
            "Epoch 13/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0494 - acc: 0.9811\n",
            "Epoch 14/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0370 - acc: 0.9871\n",
            "Epoch 15/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0629 - acc: 0.9647\n",
            "Epoch 16/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0251 - acc: 0.9835\n",
            "Epoch 17/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0174 - acc: 0.9909\n",
            "Epoch 18/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0084 - acc: 0.9955\n",
            "Epoch 19/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0190 - acc: 0.9883\n",
            "Epoch 20/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0045 - acc: 0.9982\n",
            "Epoch 21/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0097 - acc: 0.9965\n",
            "Epoch 22/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0122 - acc: 0.9909\n",
            "Epoch 23/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0161 - acc: 0.9858\n",
            "Epoch 24/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0017 - acc: 0.9984\n",
            "Epoch 25/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0177 - acc: 0.9800\n",
            "Epoch 26/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 4.7231e-04 - acc: 0.9997\n",
            "Epoch 27/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 6.0797e-04 - acc: 1.0000\n",
            "Epoch 28/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0031 - acc: 0.9960\n",
            "Epoch 29/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 7.6425e-04 - acc: 1.0000\n",
            "Epoch 30/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0019 - acc: 1.0000\n",
            "Epoch 31/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 8.1153e-04 - acc: 1.0000\n",
            "Epoch 32/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 1.1825e-04 - acc: 1.0000\n",
            "Epoch 33/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 3.0364e-04 - acc: 1.0000\n",
            "Epoch 34/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 7.0687e-05 - acc: 1.0000\n",
            "Epoch 35/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 8.0877e-05 - acc: 1.0000\n",
            "Epoch 36/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 7.8206e-05 - acc: 1.0000\n",
            "Epoch 37/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 6.6023e-06 - acc: 1.0000\n",
            "Epoch 38/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 1.7191e-06 - acc: 1.0000\n",
            "Epoch 39/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 2.5248e-06 - acc: 1.0000\n",
            "Epoch 40/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 2.8938e-06 - acc: 1.0000\n",
            "Epoch 41/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 2.2886e-06 - acc: 1.0000\n",
            "Epoch 42/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 2.2344e-06 - acc: 1.0000\n",
            "Epoch 43/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 2.6645e-07 - acc: 1.0000\n",
            "Epoch 44/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 1.5015e-06 - acc: 1.0000\n",
            "Epoch 45/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 4.6015e-07 - acc: 1.0000\n",
            "Epoch 46/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 3.4455e-08 - acc: 1.0000\n",
            "Epoch 47/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 1.7791e-08 - acc: 1.0000\n",
            "Epoch 48/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 3.4795e-08 - acc: 1.0000\n",
            "Epoch 49/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 3.6843e-08 - acc: 1.0000\n",
            "Epoch 50/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 7.8152e-09 - acc: 1.0000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7feb7d06df80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.4866 - acc: 0.7692\n",
            "processing fold # 2\n",
            "Epoch 1/50\n",
            "159/159 [==============================] - 1s 1ms/step - loss: 29.8028 - acc: 0.3990\n",
            "Epoch 2/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 3.9184 - acc: 0.6862\n",
            "Epoch 3/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 1.1537 - acc: 0.7987\n",
            "Epoch 4/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 1.0489 - acc: 0.8414\n",
            "Epoch 5/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.4649 - acc: 0.8759\n",
            "Epoch 6/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.4223 - acc: 0.9070\n",
            "Epoch 7/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.2424 - acc: 0.9653\n",
            "Epoch 8/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.1898 - acc: 0.9477\n",
            "Epoch 9/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.1802 - acc: 0.9606\n",
            "Epoch 10/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.1340 - acc: 0.9535\n",
            "Epoch 11/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0951 - acc: 0.9727\n",
            "Epoch 12/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.1091 - acc: 0.9724\n",
            "Epoch 13/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0315 - acc: 0.9942\n",
            "Epoch 14/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0403 - acc: 0.9883\n",
            "Epoch 15/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0345 - acc: 0.9939\n",
            "Epoch 16/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0275 - acc: 0.9969\n",
            "Epoch 17/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0166 - acc: 0.9987\n",
            "Epoch 18/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0062 - acc: 0.9992\n",
            "Epoch 19/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0044 - acc: 1.0000\n",
            "Epoch 20/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0211 - acc: 0.9963\n",
            "Epoch 21/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0070 - acc: 0.9979\n",
            "Epoch 22/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 23/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0074 - acc: 0.9935\n",
            "Epoch 24/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0019 - acc: 1.0000\n",
            "Epoch 25/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0023 - acc: 1.0000\n",
            "Epoch 26/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 1.4587e-04 - acc: 1.0000\n",
            "Epoch 27/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0044 - acc: 1.0000\n",
            "Epoch 28/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0030 - acc: 0.9985\n",
            "Epoch 29/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 3.0956e-04 - acc: 1.0000\n",
            "Epoch 30/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 4.4220e-04 - acc: 1.0000\n",
            "Epoch 31/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 3.8888e-04 - acc: 1.0000\n",
            "Epoch 32/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0013 - acc: 1.0000\n",
            "Epoch 33/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 2.9754e-04 - acc: 1.0000\n",
            "Epoch 34/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 5.5632e-04 - acc: 1.0000\n",
            "Epoch 35/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 2.8571e-04 - acc: 1.0000\n",
            "Epoch 36/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 4.3368e-05 - acc: 1.0000\n",
            "Epoch 37/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 1.3297e-04 - acc: 1.0000\n",
            "Epoch 38/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 2.2054e-05 - acc: 1.0000\n",
            "Epoch 39/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 2.2535e-05 - acc: 1.0000\n",
            "Epoch 40/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 2.9650e-05 - acc: 1.0000\n",
            "Epoch 41/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 7.0458e-06 - acc: 1.0000\n",
            "Epoch 42/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 3.6827e-06 - acc: 1.0000\n",
            "Epoch 43/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 1.7274e-06 - acc: 1.0000\n",
            "Epoch 44/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 3.9654e-05 - acc: 1.0000\n",
            "Epoch 45/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 2.4079e-06 - acc: 1.0000\n",
            "Epoch 46/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 3.5781e-06 - acc: 1.0000\n",
            "Epoch 47/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 5.8070e-06 - acc: 1.0000\n",
            "Epoch 48/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 6.5687e-05 - acc: 1.0000\n",
            "Epoch 49/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 6.6926e-08 - acc: 1.0000\n",
            "Epoch 50/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 1.0561e-07 - acc: 1.0000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7feb70520f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.3625 - acc: 0.8846\n",
            "processing fold # 3\n",
            "Epoch 1/50\n",
            "159/159 [==============================] - 1s 974us/step - loss: 10.8665 - acc: 0.4535\n",
            "Epoch 2/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 2.8166 - acc: 0.7806\n",
            "Epoch 3/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 1.5853 - acc: 0.8458\n",
            "Epoch 4/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.5414 - acc: 0.9063\n",
            "Epoch 5/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.6471 - acc: 0.9007\n",
            "Epoch 6/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.5627 - acc: 0.9044\n",
            "Epoch 7/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.1693 - acc: 0.9567\n",
            "Epoch 8/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0774 - acc: 0.9563\n",
            "Epoch 9/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0639 - acc: 0.9823\n",
            "Epoch 10/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0666 - acc: 0.9481\n",
            "Epoch 11/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0202 - acc: 0.9972\n",
            "Epoch 12/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0251 - acc: 0.9811\n",
            "Epoch 13/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0197 - acc: 0.9920\n",
            "Epoch 14/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0053 - acc: 0.9980\n",
            "Epoch 15/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 7.0245e-04 - acc: 1.0000\n",
            "Epoch 16/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0134 - acc: 0.9923\n",
            "Epoch 17/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0079 - acc: 1.0000\n",
            "Epoch 18/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0043 - acc: 1.0000\n",
            "Epoch 19/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0041 - acc: 0.9968\n",
            "Epoch 20/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 7.8540e-05 - acc: 1.0000\n",
            "Epoch 21/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0181 - acc: 0.9958\n",
            "Epoch 22/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0028 - acc: 1.0000\n",
            "Epoch 23/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 1.7451e-05 - acc: 1.0000\n",
            "Epoch 24/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 1.2236e-04 - acc: 1.0000\n",
            "Epoch 25/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 0.0092 - acc: 0.9981\n",
            "Epoch 26/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 8.7712e-05 - acc: 1.0000\n",
            "Epoch 27/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 2.4848e-05 - acc: 1.0000\n",
            "Epoch 28/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 6.6348e-04 - acc: 1.0000\n",
            "Epoch 29/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 5.3097e-07 - acc: 1.0000\n",
            "Epoch 30/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 2.1773e-06 - acc: 1.0000\n",
            "Epoch 31/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 1.0875e-04 - acc: 1.0000\n",
            "Epoch 32/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 8.8476e-07 - acc: 1.0000\n",
            "Epoch 33/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 1.5291e-05 - acc: 1.0000\n",
            "Epoch 34/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 2.4948e-06 - acc: 1.0000\n",
            "Epoch 35/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 7.2990e-07 - acc: 1.0000\n",
            "Epoch 36/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 4.3853e-08 - acc: 1.0000\n",
            "Epoch 37/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 9.6201e-09 - acc: 1.0000\n",
            "Epoch 38/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 7.4253e-08 - acc: 1.0000\n",
            "Epoch 39/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 4.3446e-09 - acc: 1.0000\n",
            "Epoch 40/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 2.5292e-04 - acc: 1.0000\n",
            "Epoch 41/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 3.4544e-08 - acc: 1.0000\n",
            "Epoch 42/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 7.5084e-09 - acc: 1.0000\n",
            "Epoch 43/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 2.0143e-09 - acc: 1.0000\n",
            "Epoch 44/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 1.0729e-08 - acc: 1.0000\n",
            "Epoch 45/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 1.0339e-08 - acc: 1.0000\n",
            "Epoch 46/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 1.0781e-09 - acc: 1.0000\n",
            "Epoch 47/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 7.9983e-10 - acc: 1.0000\n",
            "Epoch 48/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 1.9317e-09 - acc: 1.0000\n",
            "Epoch 49/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 1.2562e-09 - acc: 1.0000\n",
            "Epoch 50/50\n",
            "159/159 [==============================] - 0s 1ms/step - loss: 1.2656e-09 - acc: 1.0000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7feb739d4290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.5437 - acc: 0.7885\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RyaDeJkiWIS",
        "outputId": "e533937d-be25-4b09-da4f-7d988f68a228"
      },
      "source": [
        "all_scores"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.807692289352417, 0.7692307829856873, 0.8846153616905212, 0.7884615659713745]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lih34qdFic0O",
        "outputId": "2321b8ab-9fcf-4f35-c50b-ef78324aec89"
      },
      "source": [
        "np.mean(all_scores)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8125"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdZsn9mZvbzv",
        "outputId": "ccc5411c-a834-4b68-fc98-4e3cf2cf1b0c"
      },
      "source": [
        "loss, acc = model.evaluate(x_test, y_test)"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 2ms/step - loss: nan - acc: 0.4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiU1o0_0wCVU",
        "outputId": "d371fe23-a288-4fb7-ecc4-ad065f627e62"
      },
      "source": [
        "acc"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4000000059604645"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFThhlhhwQpM"
      },
      "source": [
        "pred = model.predict(x_test[0:5])"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9_30ZoGwURz"
      },
      "source": [
        ""
      ],
      "execution_count": 151,
      "outputs": []
    }
  ]
}