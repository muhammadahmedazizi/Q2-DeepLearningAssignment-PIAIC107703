{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flowers_Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXgJ6uT1NydQ"
      },
      "source": [
        "Assignment: Flowers Recognition <br>\n",
        "Dataset Description:<br>\n",
        "\n",
        "This dataset contains 4242 images of flowers.<br>\n",
        "The data collection is based on the data flicr, google images, yandex images.<br>\n",
        "You can use this datastet to recognize plants from the photo.<br>\n",
        "\n",
        "Attribute Information:<br>\n",
        "The pictures are divided into five classes: chamomile, tulip, rose, sunflower, dandelion.<br>\n",
        "For each class there are about 800 photos. Photos are not high resolution, about 320x240 pixels. <br>\n",
        "<b>Also explore how to resize images in tensorflow and then resize all the images to a same size. </b> <br>\n",
        "This is a Multiclass Classification Problem.<br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7vy-ktuOKJH"
      },
      "source": [
        "WORKFLOW : <br>\n",
        "Load Data <br>\n",
        "Split into 60 and 40 ratio.<br>\n",
        "Encode labels.<br>\n",
        "Create Model<br>\n",
        "Compilation Step (Note : Its a Multiclass Classification problem , select loss , metrics according to it)<br>\n",
        "Train the Model.<br>\n",
        "If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .<br>\n",
        "Prediction should be > 85%<br>\n",
        "Evaluation Step<br>\n",
        "Prediction<br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri3Bg5qfPRic"
      },
      "source": [
        "Data : <br>\n",
        "https://drive.google.com/file/d/1-OX6wn5gA-bJpjPNfSyaYQLz-A-AB_uj/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTtg3WuGTA1o"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvucbOxuy8c0"
      },
      "source": [
        "### IMAGE PREPROCESSING DONE AT LOCAL SYSTEM AND BROUGHT THE DATA IN SHAPE OF CSV TO COLAB - THE PREPROCESSING IS DONE USING FOLLOWING SCRIPT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXQZcr4vz2p3"
      },
      "source": [
        "#### IMAGE RESIZE AND GRESCALE SCRIPT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtAzec8TzE99"
      },
      "source": [
        "import os\n",
        "# import numpy as np\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "path = \"images/\"\n",
        "\n",
        "\n",
        "# This will resise the Image to 50 x 50.\n",
        "def image_resize(path,filename):\n",
        "    load_img_rz = np.array(Image.open(os.path.join(path, filename)).resize((50, 50)))\n",
        "    Image.fromarray(load_img_rz).save(os.path.join(path, filename))\n",
        "\n",
        "# This will convert image into greyscale\n",
        "# Warning This will replace the files\n",
        "def save_as_greyscale(path,filename):\n",
        "    im = np.array(Image.open(os.path.join(path, filename)).convert('L'))  # you can pass multiple arguments in single line\n",
        "    gr_im = Image.fromarray(im).save(os.path.join(path,filename))\n",
        "\n",
        "\n",
        "\n",
        "for dirpath, dirnames, filenames in os.walk(path):\n",
        "    for filename in filenames:\n",
        "        file_name_with_path = os.path.join(dirpath, filename)\n",
        "        bn = os.path.basename(filename)\n",
        "        save_as_greyscale(dirpath,filename)\n",
        "        image_resize(dirpath,filename)\n",
        "        print (file_name_with_path)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXlnoQ5az_UY"
      },
      "source": [
        "#### CONVERTED IMAGES INTO NUMPY ARRAY WITH LABELS FROM DIRECTORY NAME USING FOLLOIWNG SCRIPT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjLrkbnH0LtC"
      },
      "source": [
        "from numpy import asarray\n",
        "from PIL import Image\n",
        "#import pandas as pd\n",
        "# import numpy as np\n",
        "# import os\n",
        "\n",
        "# Path of Images Directory\n",
        "path = \"images/flowers/\"\n",
        "\n",
        "# Creating a blank dataframe\n",
        "df = pd.DataFrame()\n",
        "\n",
        "# Creating a blank list\n",
        "listt = []\n",
        "\n",
        "# This function will convert image to numpy array and flatten the received array\n",
        "# Function Arguments : file path and directory name as flower label\n",
        "def image_to_numpy_flaten(path, fl_label):\n",
        "    image = Image.open(path)\n",
        "    numpydata = asarray(image)\n",
        "    fdata = numpydata.flatten()\n",
        "    fdata = np.append(fdata, fl_label)\n",
        "    return fdata\n",
        "\n",
        "\n",
        "# For loop with Os.walk\n",
        "# Creating Label Name from directory name\n",
        "# Calling Function image_to_numpy_flatten\n",
        "\n",
        "for dirpath, dirnames, filenames in os.walk(path):\n",
        "    for filename in filenames:\n",
        "        label = dirpath.split(\"/\")\n",
        "        label = label[-1].split(\"\\\\\")\n",
        "        label = label[-1]\n",
        "        result = image_to_numpy_flaten(os.path.join(dirpath,filename), label)\n",
        "        listt.append(result)\n",
        "\n",
        "\n",
        "\n",
        "newvar = pd.DataFrame(listt)\n",
        "newvar.to_csv('flower_data.csv', mode='a', index=False, header=False)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzTRSP6b0RzX"
      },
      "source": [
        "#### LOADING CSV FILE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOhy3Qr60U8g",
        "outputId": "5bd59a6b-484a-47ce-ac97-0ae807fca032"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASIfpYOM0ytc"
      },
      "source": [
        "data = pd.read_csv('/content/gdrive/MyDrive/flower_data.csv', header=None, index_col=False)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "tWIzKhla1Lz8",
        "outputId": "98a81448-d754-4440-bfdb-90ac825f66f8"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>2461</th>\n",
              "      <th>2462</th>\n",
              "      <th>2463</th>\n",
              "      <th>2464</th>\n",
              "      <th>2465</th>\n",
              "      <th>2466</th>\n",
              "      <th>2467</th>\n",
              "      <th>2468</th>\n",
              "      <th>2469</th>\n",
              "      <th>2470</th>\n",
              "      <th>2471</th>\n",
              "      <th>2472</th>\n",
              "      <th>2473</th>\n",
              "      <th>2474</th>\n",
              "      <th>2475</th>\n",
              "      <th>2476</th>\n",
              "      <th>2477</th>\n",
              "      <th>2478</th>\n",
              "      <th>2479</th>\n",
              "      <th>2480</th>\n",
              "      <th>2481</th>\n",
              "      <th>2482</th>\n",
              "      <th>2483</th>\n",
              "      <th>2484</th>\n",
              "      <th>2485</th>\n",
              "      <th>2486</th>\n",
              "      <th>2487</th>\n",
              "      <th>2488</th>\n",
              "      <th>2489</th>\n",
              "      <th>2490</th>\n",
              "      <th>2491</th>\n",
              "      <th>2492</th>\n",
              "      <th>2493</th>\n",
              "      <th>2494</th>\n",
              "      <th>2495</th>\n",
              "      <th>2496</th>\n",
              "      <th>2497</th>\n",
              "      <th>2498</th>\n",
              "      <th>2499</th>\n",
              "      <th>2500</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>138</td>\n",
              "      <td>154</td>\n",
              "      <td>167</td>\n",
              "      <td>168</td>\n",
              "      <td>162</td>\n",
              "      <td>156</td>\n",
              "      <td>152</td>\n",
              "      <td>149</td>\n",
              "      <td>147</td>\n",
              "      <td>150</td>\n",
              "      <td>146</td>\n",
              "      <td>141</td>\n",
              "      <td>152</td>\n",
              "      <td>169</td>\n",
              "      <td>169</td>\n",
              "      <td>157</td>\n",
              "      <td>162</td>\n",
              "      <td>162</td>\n",
              "      <td>167</td>\n",
              "      <td>173</td>\n",
              "      <td>171</td>\n",
              "      <td>166</td>\n",
              "      <td>168</td>\n",
              "      <td>175</td>\n",
              "      <td>173</td>\n",
              "      <td>168</td>\n",
              "      <td>169</td>\n",
              "      <td>162</td>\n",
              "      <td>149</td>\n",
              "      <td>156</td>\n",
              "      <td>175</td>\n",
              "      <td>183</td>\n",
              "      <td>179</td>\n",
              "      <td>164</td>\n",
              "      <td>147</td>\n",
              "      <td>142</td>\n",
              "      <td>150</td>\n",
              "      <td>160</td>\n",
              "      <td>166</td>\n",
              "      <td>166</td>\n",
              "      <td>...</td>\n",
              "      <td>124</td>\n",
              "      <td>124</td>\n",
              "      <td>137</td>\n",
              "      <td>169</td>\n",
              "      <td>171</td>\n",
              "      <td>175</td>\n",
              "      <td>179</td>\n",
              "      <td>182</td>\n",
              "      <td>177</td>\n",
              "      <td>166</td>\n",
              "      <td>152</td>\n",
              "      <td>143</td>\n",
              "      <td>138</td>\n",
              "      <td>171</td>\n",
              "      <td>174</td>\n",
              "      <td>164</td>\n",
              "      <td>176</td>\n",
              "      <td>187</td>\n",
              "      <td>185</td>\n",
              "      <td>180</td>\n",
              "      <td>156</td>\n",
              "      <td>146</td>\n",
              "      <td>126</td>\n",
              "      <td>132</td>\n",
              "      <td>181</td>\n",
              "      <td>178</td>\n",
              "      <td>171</td>\n",
              "      <td>156</td>\n",
              "      <td>164</td>\n",
              "      <td>174</td>\n",
              "      <td>175</td>\n",
              "      <td>165</td>\n",
              "      <td>145</td>\n",
              "      <td>133</td>\n",
              "      <td>133</td>\n",
              "      <td>135</td>\n",
              "      <td>133</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>daisy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>225</td>\n",
              "      <td>217</td>\n",
              "      <td>221</td>\n",
              "      <td>227</td>\n",
              "      <td>219</td>\n",
              "      <td>132</td>\n",
              "      <td>63</td>\n",
              "      <td>124</td>\n",
              "      <td>189</td>\n",
              "      <td>183</td>\n",
              "      <td>197</td>\n",
              "      <td>184</td>\n",
              "      <td>208</td>\n",
              "      <td>163</td>\n",
              "      <td>137</td>\n",
              "      <td>184</td>\n",
              "      <td>160</td>\n",
              "      <td>133</td>\n",
              "      <td>126</td>\n",
              "      <td>125</td>\n",
              "      <td>113</td>\n",
              "      <td>117</td>\n",
              "      <td>131</td>\n",
              "      <td>130</td>\n",
              "      <td>139</td>\n",
              "      <td>138</td>\n",
              "      <td>139</td>\n",
              "      <td>143</td>\n",
              "      <td>147</td>\n",
              "      <td>147</td>\n",
              "      <td>141</td>\n",
              "      <td>136</td>\n",
              "      <td>121</td>\n",
              "      <td>139</td>\n",
              "      <td>116</td>\n",
              "      <td>144</td>\n",
              "      <td>109</td>\n",
              "      <td>8</td>\n",
              "      <td>23</td>\n",
              "      <td>60</td>\n",
              "      <td>...</td>\n",
              "      <td>236</td>\n",
              "      <td>204</td>\n",
              "      <td>228</td>\n",
              "      <td>232</td>\n",
              "      <td>240</td>\n",
              "      <td>247</td>\n",
              "      <td>244</td>\n",
              "      <td>241</td>\n",
              "      <td>231</td>\n",
              "      <td>222</td>\n",
              "      <td>233</td>\n",
              "      <td>243</td>\n",
              "      <td>237</td>\n",
              "      <td>222</td>\n",
              "      <td>214</td>\n",
              "      <td>216</td>\n",
              "      <td>230</td>\n",
              "      <td>237</td>\n",
              "      <td>226</td>\n",
              "      <td>211</td>\n",
              "      <td>203</td>\n",
              "      <td>173</td>\n",
              "      <td>139</td>\n",
              "      <td>149</td>\n",
              "      <td>140</td>\n",
              "      <td>107</td>\n",
              "      <td>105</td>\n",
              "      <td>107</td>\n",
              "      <td>104</td>\n",
              "      <td>113</td>\n",
              "      <td>116</td>\n",
              "      <td>107</td>\n",
              "      <td>104</td>\n",
              "      <td>109</td>\n",
              "      <td>145</td>\n",
              "      <td>173</td>\n",
              "      <td>142</td>\n",
              "      <td>137</td>\n",
              "      <td>164</td>\n",
              "      <td>daisy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>102</td>\n",
              "      <td>87</td>\n",
              "      <td>89</td>\n",
              "      <td>76</td>\n",
              "      <td>93</td>\n",
              "      <td>126</td>\n",
              "      <td>115</td>\n",
              "      <td>113</td>\n",
              "      <td>147</td>\n",
              "      <td>123</td>\n",
              "      <td>133</td>\n",
              "      <td>158</td>\n",
              "      <td>131</td>\n",
              "      <td>156</td>\n",
              "      <td>128</td>\n",
              "      <td>156</td>\n",
              "      <td>148</td>\n",
              "      <td>114</td>\n",
              "      <td>94</td>\n",
              "      <td>100</td>\n",
              "      <td>90</td>\n",
              "      <td>103</td>\n",
              "      <td>138</td>\n",
              "      <td>125</td>\n",
              "      <td>111</td>\n",
              "      <td>108</td>\n",
              "      <td>123</td>\n",
              "      <td>111</td>\n",
              "      <td>107</td>\n",
              "      <td>123</td>\n",
              "      <td>124</td>\n",
              "      <td>119</td>\n",
              "      <td>129</td>\n",
              "      <td>137</td>\n",
              "      <td>126</td>\n",
              "      <td>143</td>\n",
              "      <td>133</td>\n",
              "      <td>132</td>\n",
              "      <td>115</td>\n",
              "      <td>132</td>\n",
              "      <td>...</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>27</td>\n",
              "      <td>31</td>\n",
              "      <td>22</td>\n",
              "      <td>13</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>22</td>\n",
              "      <td>61</td>\n",
              "      <td>142</td>\n",
              "      <td>217</td>\n",
              "      <td>114</td>\n",
              "      <td>97</td>\n",
              "      <td>204</td>\n",
              "      <td>119</td>\n",
              "      <td>44</td>\n",
              "      <td>11</td>\n",
              "      <td>20</td>\n",
              "      <td>6</td>\n",
              "      <td>21</td>\n",
              "      <td>19</td>\n",
              "      <td>19</td>\n",
              "      <td>23</td>\n",
              "      <td>24</td>\n",
              "      <td>25</td>\n",
              "      <td>31</td>\n",
              "      <td>39</td>\n",
              "      <td>35</td>\n",
              "      <td>36</td>\n",
              "      <td>38</td>\n",
              "      <td>37</td>\n",
              "      <td>29</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>26</td>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "      <td>daisy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>26</td>\n",
              "      <td>28</td>\n",
              "      <td>33</td>\n",
              "      <td>33</td>\n",
              "      <td>36</td>\n",
              "      <td>37</td>\n",
              "      <td>31</td>\n",
              "      <td>43</td>\n",
              "      <td>37</td>\n",
              "      <td>53</td>\n",
              "      <td>35</td>\n",
              "      <td>27</td>\n",
              "      <td>49</td>\n",
              "      <td>43</td>\n",
              "      <td>44</td>\n",
              "      <td>40</td>\n",
              "      <td>57</td>\n",
              "      <td>52</td>\n",
              "      <td>54</td>\n",
              "      <td>55</td>\n",
              "      <td>58</td>\n",
              "      <td>69</td>\n",
              "      <td>59</td>\n",
              "      <td>57</td>\n",
              "      <td>81</td>\n",
              "      <td>72</td>\n",
              "      <td>70</td>\n",
              "      <td>78</td>\n",
              "      <td>72</td>\n",
              "      <td>57</td>\n",
              "      <td>29</td>\n",
              "      <td>23</td>\n",
              "      <td>16</td>\n",
              "      <td>35</td>\n",
              "      <td>57</td>\n",
              "      <td>22</td>\n",
              "      <td>48</td>\n",
              "      <td>73</td>\n",
              "      <td>70</td>\n",
              "      <td>...</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>19</td>\n",
              "      <td>21</td>\n",
              "      <td>22</td>\n",
              "      <td>19</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>19</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>19</td>\n",
              "      <td>21</td>\n",
              "      <td>20</td>\n",
              "      <td>18</td>\n",
              "      <td>16</td>\n",
              "      <td>17</td>\n",
              "      <td>21</td>\n",
              "      <td>22</td>\n",
              "      <td>20</td>\n",
              "      <td>18</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>daisy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17</td>\n",
              "      <td>29</td>\n",
              "      <td>42</td>\n",
              "      <td>42</td>\n",
              "      <td>47</td>\n",
              "      <td>45</td>\n",
              "      <td>32</td>\n",
              "      <td>39</td>\n",
              "      <td>38</td>\n",
              "      <td>45</td>\n",
              "      <td>53</td>\n",
              "      <td>73</td>\n",
              "      <td>71</td>\n",
              "      <td>52</td>\n",
              "      <td>48</td>\n",
              "      <td>48</td>\n",
              "      <td>34</td>\n",
              "      <td>41</td>\n",
              "      <td>26</td>\n",
              "      <td>31</td>\n",
              "      <td>36</td>\n",
              "      <td>29</td>\n",
              "      <td>46</td>\n",
              "      <td>60</td>\n",
              "      <td>62</td>\n",
              "      <td>60</td>\n",
              "      <td>36</td>\n",
              "      <td>29</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>27</td>\n",
              "      <td>20</td>\n",
              "      <td>23</td>\n",
              "      <td>32</td>\n",
              "      <td>33</td>\n",
              "      <td>22</td>\n",
              "      <td>16</td>\n",
              "      <td>18</td>\n",
              "      <td>20</td>\n",
              "      <td>17</td>\n",
              "      <td>...</td>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "      <td>25</td>\n",
              "      <td>26</td>\n",
              "      <td>27</td>\n",
              "      <td>30</td>\n",
              "      <td>30</td>\n",
              "      <td>29</td>\n",
              "      <td>28</td>\n",
              "      <td>33</td>\n",
              "      <td>38</td>\n",
              "      <td>37</td>\n",
              "      <td>31</td>\n",
              "      <td>30</td>\n",
              "      <td>29</td>\n",
              "      <td>28</td>\n",
              "      <td>27</td>\n",
              "      <td>28</td>\n",
              "      <td>29</td>\n",
              "      <td>31</td>\n",
              "      <td>32</td>\n",
              "      <td>30</td>\n",
              "      <td>32</td>\n",
              "      <td>34</td>\n",
              "      <td>33</td>\n",
              "      <td>30</td>\n",
              "      <td>28</td>\n",
              "      <td>26</td>\n",
              "      <td>26</td>\n",
              "      <td>24</td>\n",
              "      <td>29</td>\n",
              "      <td>33</td>\n",
              "      <td>32</td>\n",
              "      <td>28</td>\n",
              "      <td>26</td>\n",
              "      <td>29</td>\n",
              "      <td>33</td>\n",
              "      <td>31</td>\n",
              "      <td>32</td>\n",
              "      <td>daisy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 2501 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0     1     2     3     4     5     ...  2495  2496  2497  2498  2499   2500\n",
              "0   138   154   167   168   162   156  ...   133   135   133   128   128  daisy\n",
              "1   225   217   221   227   219   132  ...   145   173   142   137   164  daisy\n",
              "2   102    87    89    76    93   126  ...    20    20    26    35    35  daisy\n",
              "3    33    26    28    33    33    36  ...    22    20    18    22    22  daisy\n",
              "4    17    29    42    42    47    45  ...    26    29    33    31    32  daisy\n",
              "\n",
              "[5 rows x 2501 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiJ5J9SBTyx0"
      },
      "source": [
        "### Checking Null Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lx_PU7oe2EX-",
        "outputId": "6d51c6d5-5487-43fc-e683-82a60ae2af95"
      },
      "source": [
        "data.isnull().sum()\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0\n",
              "1       0\n",
              "2       0\n",
              "3       0\n",
              "4       0\n",
              "       ..\n",
              "2496    0\n",
              "2497    0\n",
              "2498    0\n",
              "2499    0\n",
              "2500    0\n",
              "Length: 2501, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0nzPsXr2R_d",
        "outputId": "4c5855ea-5c4c-453f-edb6-7145f0444d9e"
      },
      "source": [
        "data.info"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.info of       0     1     2     3     4     5     ...  2495  2496  2497  2498  2499   2500\n",
              "0      138   154   167   168   162   156  ...   133   135   133   128   128  daisy\n",
              "1      225   217   221   227   219   132  ...   145   173   142   137   164  daisy\n",
              "2      102    87    89    76    93   126  ...    20    20    26    35    35  daisy\n",
              "3       33    26    28    33    33    36  ...    22    20    18    22    22  daisy\n",
              "4       17    29    42    42    47    45  ...    26    29    33    31    32  daisy\n",
              "...    ...   ...   ...   ...   ...   ...  ...   ...   ...   ...   ...   ...    ...\n",
              "4318   203   217   201   197    56    96  ...    23    46   107   133   167  tulip\n",
              "4319   135   132   124   123   135   147  ...    51    62    79    99   114  tulip\n",
              "4320    80    79    82    89    90    86  ...    84    83    85    79    79  tulip\n",
              "4321   181   201   166   153   130   183  ...    33    20    26    21    34  tulip\n",
              "4322    46    93   101   123   106   140  ...    75    78    52    50    52  tulip\n",
              "\n",
              "[4323 rows x 2501 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g143xMx4GtPY",
        "outputId": "b124210a-b546-4901-b3de-af3634e1a08a"
      },
      "source": [
        "data[0].shape # Already Flatten "
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4323,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCFuGhQD6x9X"
      },
      "source": [
        "### Data Shuffling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShIc_vef6yPZ"
      },
      "source": [
        "data = data.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "gUIFWJVl63jV",
        "outputId": "9ff7df54-c699-4ace-cc2c-2f6304bfb0d6"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>2461</th>\n",
              "      <th>2462</th>\n",
              "      <th>2463</th>\n",
              "      <th>2464</th>\n",
              "      <th>2465</th>\n",
              "      <th>2466</th>\n",
              "      <th>2467</th>\n",
              "      <th>2468</th>\n",
              "      <th>2469</th>\n",
              "      <th>2470</th>\n",
              "      <th>2471</th>\n",
              "      <th>2472</th>\n",
              "      <th>2473</th>\n",
              "      <th>2474</th>\n",
              "      <th>2475</th>\n",
              "      <th>2476</th>\n",
              "      <th>2477</th>\n",
              "      <th>2478</th>\n",
              "      <th>2479</th>\n",
              "      <th>2480</th>\n",
              "      <th>2481</th>\n",
              "      <th>2482</th>\n",
              "      <th>2483</th>\n",
              "      <th>2484</th>\n",
              "      <th>2485</th>\n",
              "      <th>2486</th>\n",
              "      <th>2487</th>\n",
              "      <th>2488</th>\n",
              "      <th>2489</th>\n",
              "      <th>2490</th>\n",
              "      <th>2491</th>\n",
              "      <th>2492</th>\n",
              "      <th>2493</th>\n",
              "      <th>2494</th>\n",
              "      <th>2495</th>\n",
              "      <th>2496</th>\n",
              "      <th>2497</th>\n",
              "      <th>2498</th>\n",
              "      <th>2499</th>\n",
              "      <th>2500</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>172</td>\n",
              "      <td>164</td>\n",
              "      <td>157</td>\n",
              "      <td>161</td>\n",
              "      <td>167</td>\n",
              "      <td>160</td>\n",
              "      <td>133</td>\n",
              "      <td>108</td>\n",
              "      <td>131</td>\n",
              "      <td>126</td>\n",
              "      <td>138</td>\n",
              "      <td>142</td>\n",
              "      <td>113</td>\n",
              "      <td>83</td>\n",
              "      <td>79</td>\n",
              "      <td>88</td>\n",
              "      <td>105</td>\n",
              "      <td>133</td>\n",
              "      <td>116</td>\n",
              "      <td>100</td>\n",
              "      <td>107</td>\n",
              "      <td>121</td>\n",
              "      <td>87</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>50</td>\n",
              "      <td>101</td>\n",
              "      <td>55</td>\n",
              "      <td>71</td>\n",
              "      <td>68</td>\n",
              "      <td>87</td>\n",
              "      <td>87</td>\n",
              "      <td>72</td>\n",
              "      <td>87</td>\n",
              "      <td>45</td>\n",
              "      <td>31</td>\n",
              "      <td>42</td>\n",
              "      <td>41</td>\n",
              "      <td>55</td>\n",
              "      <td>50</td>\n",
              "      <td>...</td>\n",
              "      <td>39</td>\n",
              "      <td>37</td>\n",
              "      <td>53</td>\n",
              "      <td>74</td>\n",
              "      <td>73</td>\n",
              "      <td>78</td>\n",
              "      <td>67</td>\n",
              "      <td>73</td>\n",
              "      <td>85</td>\n",
              "      <td>84</td>\n",
              "      <td>76</td>\n",
              "      <td>62</td>\n",
              "      <td>44</td>\n",
              "      <td>39</td>\n",
              "      <td>44</td>\n",
              "      <td>55</td>\n",
              "      <td>68</td>\n",
              "      <td>79</td>\n",
              "      <td>85</td>\n",
              "      <td>84</td>\n",
              "      <td>82</td>\n",
              "      <td>78</td>\n",
              "      <td>84</td>\n",
              "      <td>80</td>\n",
              "      <td>66</td>\n",
              "      <td>45</td>\n",
              "      <td>23</td>\n",
              "      <td>29</td>\n",
              "      <td>59</td>\n",
              "      <td>43</td>\n",
              "      <td>26</td>\n",
              "      <td>40</td>\n",
              "      <td>48</td>\n",
              "      <td>49</td>\n",
              "      <td>57</td>\n",
              "      <td>56</td>\n",
              "      <td>64</td>\n",
              "      <td>55</td>\n",
              "      <td>53</td>\n",
              "      <td>rose</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>23</td>\n",
              "      <td>24</td>\n",
              "      <td>61</td>\n",
              "      <td>73</td>\n",
              "      <td>39</td>\n",
              "      <td>19</td>\n",
              "      <td>21</td>\n",
              "      <td>25</td>\n",
              "      <td>31</td>\n",
              "      <td>31</td>\n",
              "      <td>22</td>\n",
              "      <td>29</td>\n",
              "      <td>9</td>\n",
              "      <td>27</td>\n",
              "      <td>37</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>29</td>\n",
              "      <td>24</td>\n",
              "      <td>29</td>\n",
              "      <td>40</td>\n",
              "      <td>39</td>\n",
              "      <td>36</td>\n",
              "      <td>27</td>\n",
              "      <td>2</td>\n",
              "      <td>38</td>\n",
              "      <td>26</td>\n",
              "      <td>29</td>\n",
              "      <td>23</td>\n",
              "      <td>28</td>\n",
              "      <td>39</td>\n",
              "      <td>36</td>\n",
              "      <td>21</td>\n",
              "      <td>19</td>\n",
              "      <td>29</td>\n",
              "      <td>...</td>\n",
              "      <td>8</td>\n",
              "      <td>28</td>\n",
              "      <td>39</td>\n",
              "      <td>28</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>17</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>rose</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>232</td>\n",
              "      <td>231</td>\n",
              "      <td>230</td>\n",
              "      <td>229</td>\n",
              "      <td>226</td>\n",
              "      <td>223</td>\n",
              "      <td>221</td>\n",
              "      <td>220</td>\n",
              "      <td>219</td>\n",
              "      <td>218</td>\n",
              "      <td>215</td>\n",
              "      <td>214</td>\n",
              "      <td>217</td>\n",
              "      <td>220</td>\n",
              "      <td>219</td>\n",
              "      <td>216</td>\n",
              "      <td>221</td>\n",
              "      <td>218</td>\n",
              "      <td>217</td>\n",
              "      <td>222</td>\n",
              "      <td>211</td>\n",
              "      <td>203</td>\n",
              "      <td>211</td>\n",
              "      <td>206</td>\n",
              "      <td>209</td>\n",
              "      <td>195</td>\n",
              "      <td>194</td>\n",
              "      <td>199</td>\n",
              "      <td>194</td>\n",
              "      <td>196</td>\n",
              "      <td>204</td>\n",
              "      <td>206</td>\n",
              "      <td>205</td>\n",
              "      <td>206</td>\n",
              "      <td>209</td>\n",
              "      <td>209</td>\n",
              "      <td>207</td>\n",
              "      <td>205</td>\n",
              "      <td>209</td>\n",
              "      <td>214</td>\n",
              "      <td>...</td>\n",
              "      <td>133</td>\n",
              "      <td>120</td>\n",
              "      <td>161</td>\n",
              "      <td>192</td>\n",
              "      <td>109</td>\n",
              "      <td>96</td>\n",
              "      <td>140</td>\n",
              "      <td>166</td>\n",
              "      <td>169</td>\n",
              "      <td>133</td>\n",
              "      <td>128</td>\n",
              "      <td>56</td>\n",
              "      <td>64</td>\n",
              "      <td>94</td>\n",
              "      <td>78</td>\n",
              "      <td>144</td>\n",
              "      <td>122</td>\n",
              "      <td>88</td>\n",
              "      <td>115</td>\n",
              "      <td>143</td>\n",
              "      <td>168</td>\n",
              "      <td>168</td>\n",
              "      <td>139</td>\n",
              "      <td>134</td>\n",
              "      <td>132</td>\n",
              "      <td>144</td>\n",
              "      <td>129</td>\n",
              "      <td>150</td>\n",
              "      <td>172</td>\n",
              "      <td>133</td>\n",
              "      <td>119</td>\n",
              "      <td>85</td>\n",
              "      <td>134</td>\n",
              "      <td>184</td>\n",
              "      <td>155</td>\n",
              "      <td>122</td>\n",
              "      <td>91</td>\n",
              "      <td>112</td>\n",
              "      <td>142</td>\n",
              "      <td>tulip</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>94</td>\n",
              "      <td>93</td>\n",
              "      <td>92</td>\n",
              "      <td>91</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>89</td>\n",
              "      <td>86</td>\n",
              "      <td>82</td>\n",
              "      <td>78</td>\n",
              "      <td>77</td>\n",
              "      <td>77</td>\n",
              "      <td>78</td>\n",
              "      <td>79</td>\n",
              "      <td>80</td>\n",
              "      <td>81</td>\n",
              "      <td>82</td>\n",
              "      <td>84</td>\n",
              "      <td>85</td>\n",
              "      <td>85</td>\n",
              "      <td>86</td>\n",
              "      <td>86</td>\n",
              "      <td>89</td>\n",
              "      <td>88</td>\n",
              "      <td>87</td>\n",
              "      <td>86</td>\n",
              "      <td>85</td>\n",
              "      <td>84</td>\n",
              "      <td>83</td>\n",
              "      <td>82</td>\n",
              "      <td>81</td>\n",
              "      <td>80</td>\n",
              "      <td>78</td>\n",
              "      <td>76</td>\n",
              "      <td>75</td>\n",
              "      <td>74</td>\n",
              "      <td>74</td>\n",
              "      <td>74</td>\n",
              "      <td>...</td>\n",
              "      <td>42</td>\n",
              "      <td>39</td>\n",
              "      <td>34</td>\n",
              "      <td>27</td>\n",
              "      <td>22</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>19</td>\n",
              "      <td>20</td>\n",
              "      <td>21</td>\n",
              "      <td>22</td>\n",
              "      <td>23</td>\n",
              "      <td>24</td>\n",
              "      <td>23</td>\n",
              "      <td>24</td>\n",
              "      <td>25</td>\n",
              "      <td>26</td>\n",
              "      <td>27</td>\n",
              "      <td>28</td>\n",
              "      <td>27</td>\n",
              "      <td>27</td>\n",
              "      <td>28</td>\n",
              "      <td>30</td>\n",
              "      <td>32</td>\n",
              "      <td>33</td>\n",
              "      <td>33</td>\n",
              "      <td>35</td>\n",
              "      <td>38</td>\n",
              "      <td>41</td>\n",
              "      <td>42</td>\n",
              "      <td>42</td>\n",
              "      <td>43</td>\n",
              "      <td>44</td>\n",
              "      <td>46</td>\n",
              "      <td>47</td>\n",
              "      <td>48</td>\n",
              "      <td>48</td>\n",
              "      <td>51</td>\n",
              "      <td>51</td>\n",
              "      <td>daisy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>96</td>\n",
              "      <td>96</td>\n",
              "      <td>75</td>\n",
              "      <td>37</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>21</td>\n",
              "      <td>27</td>\n",
              "      <td>26</td>\n",
              "      <td>23</td>\n",
              "      <td>27</td>\n",
              "      <td>34</td>\n",
              "      <td>33</td>\n",
              "      <td>21</td>\n",
              "      <td>16</td>\n",
              "      <td>19</td>\n",
              "      <td>17</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>74</td>\n",
              "      <td>119</td>\n",
              "      <td>162</td>\n",
              "      <td>170</td>\n",
              "      <td>180</td>\n",
              "      <td>112</td>\n",
              "      <td>66</td>\n",
              "      <td>61</td>\n",
              "      <td>69</td>\n",
              "      <td>82</td>\n",
              "      <td>103</td>\n",
              "      <td>89</td>\n",
              "      <td>67</td>\n",
              "      <td>71</td>\n",
              "      <td>88</td>\n",
              "      <td>85</td>\n",
              "      <td>78</td>\n",
              "      <td>80</td>\n",
              "      <td>70</td>\n",
              "      <td>64</td>\n",
              "      <td>80</td>\n",
              "      <td>65</td>\n",
              "      <td>63</td>\n",
              "      <td>63</td>\n",
              "      <td>62</td>\n",
              "      <td>57</td>\n",
              "      <td>51</td>\n",
              "      <td>52</td>\n",
              "      <td>58</td>\n",
              "      <td>70</td>\n",
              "      <td>69</td>\n",
              "      <td>63</td>\n",
              "      <td>53</td>\n",
              "      <td>47</td>\n",
              "      <td>46</td>\n",
              "      <td>44</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>36</td>\n",
              "      <td>rose</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 2501 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0     1     2     3     4     5     ...  2495  2496  2497  2498  2499   2500\n",
              "0   172   164   157   161   167   160  ...    57    56    64    55    53   rose\n",
              "1    15    10     6     1    16    23  ...     2     1     0     0     0   rose\n",
              "2   232   231   230   229   226   223  ...   155   122    91   112   142  tulip\n",
              "3    94    93    92    91    90    90  ...    47    48    48    51    51  daisy\n",
              "4    96    96    75    37    11     8  ...    46    44    40    35    36   rose\n",
              "\n",
              "[5 rows x 2501 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMKGLTGx2ifs"
      },
      "source": [
        "# Separating Input and Output Colmumns \n",
        "X = data.iloc[:, :-1].values  # Input Columns\n",
        "Y = data.iloc[:, -1:].values # Output Columns "
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxWRJVpF6C7i",
        "outputId": "f4833b13-787b-4376-e9e0-33d08fd19524"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4323, 2500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3jyTmDg6E7T",
        "outputId": "82ee79bb-c955-4c4f-f63a-f24287475d1b"
      },
      "source": [
        "Y.shape"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4323, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNTxb8dzSixu"
      },
      "source": [
        "### Splitting Data into Train, Text and Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HfqH2vH6Qjt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe750c31-0336-467c-c18f-217db9c8df3d"
      },
      "source": [
        "# Total Images 4323 - Data Split\n",
        "\n",
        "def split_train_val_test(x, y, train, val, test):\n",
        "    x_rows, x_col = x.shape\n",
        "    y_rows, y_col = y.shape \n",
        "    \n",
        "    train_start = 0\n",
        "    train_stop = int(x_rows*train)\n",
        "    \n",
        "    val_start = train_stop\n",
        "    val_stop = int(x_rows*train)+int(x_rows*val)\n",
        "    \n",
        "    test_start = val_stop\n",
        "    test_stop = None\n",
        "\n",
        "    x_train = x[train_start:train_stop,] # Extracting X_Training Data \n",
        "    x_val = x[val_start:val_stop,]\n",
        "    x_test = x[test_start:test_stop]\n",
        "    \n",
        "    y_train = y[train_start:train_stop,] # Extracting y_Training Data \n",
        "    y_val = y[val_start:val_stop,]\n",
        "    y_test = y[test_start:test_stop]\n",
        "    \n",
        "    #Splitting Desicription \n",
        "    desc = f'''Splitting Discription:\n",
        "    Training Data {int(train*100)}%\n",
        "    Validation Data {int(val*100)}%\n",
        "    Testing Data {int(val*100)}%\n",
        "    \n",
        "    Shape of Training Data {x.shape}\n",
        "    Shape of Target Data {y.shape}\n",
        "    \n",
        "    Shape of x_train {x_train.shape}\n",
        "    Shape of x_val {x_val.shape}\n",
        "    Shape of x_test {x_test.shape}\n",
        "     \n",
        "    Shape of y_train {y_train.shape}\n",
        "    Shape of y_val {y_val.shape}\n",
        "    Shape of y_test {y_test.shape}\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    return x_train, x_val, x_test, y_train, y_val, y_test, desc\n",
        "\n",
        "\n",
        "\n",
        "x_train, x_val, x_test, y_train, y_val, y_test, desc = split_train_val_test(X,Y,.6,.2,.2)\n",
        "\n",
        "print (desc)\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Splitting Discription:\n",
            "    Training Data 60%\n",
            "    Validation Data 20%\n",
            "    Testing Data 20%\n",
            "    \n",
            "    Shape of Training Data (4323, 2500)\n",
            "    Shape of Target Data (4323, 1)\n",
            "    \n",
            "    Shape of x_train (2593, 2500)\n",
            "    Shape of x_val (864, 2500)\n",
            "    Shape of x_test (866, 2500)\n",
            "     \n",
            "    Shape of y_train (2593, 1)\n",
            "    Shape of y_val (864, 1)\n",
            "    Shape of y_test (866, 1)\n",
            "    \n",
            "    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRAl9uXW8ko6",
        "outputId": "998287bd-70c5-48f5-e7cc-4bb7cd41a64c"
      },
      "source": [
        "print (x_train.shape, x_test.shape, x_val.shape)\n",
        "print (y_train.shape, y_test.shape, y_val.shape)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2593, 2500) (866, 2500) (864, 2500)\n",
            "(2593, 1) (866, 1) (864, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZSFNkm6HSUR"
      },
      "source": [
        "# Normalization "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2lMbBqOHVxY"
      },
      "source": [
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "x_val = x_val.astype('float32') / 255\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNHAAx45Hzxu",
        "outputId": "e394a634-a2f5-4795-e209-74087406002f"
      },
      "source": [
        "x_train # After Normalization "
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.6745098 , 0.6431373 , 0.6156863 , ..., 0.2509804 , 0.21568628,\n",
              "        0.20784314],\n",
              "       [0.05882353, 0.03921569, 0.02352941, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.9098039 , 0.90588236, 0.9019608 , ..., 0.35686275, 0.4392157 ,\n",
              "        0.5568628 ],\n",
              "       ...,\n",
              "       [0.14901961, 0.15686275, 0.16078432, ..., 0.11764706, 0.12941177,\n",
              "        0.12156863],\n",
              "       [0.18039216, 0.19607843, 0.21960784, ..., 0.5176471 , 0.5019608 ,\n",
              "        0.5019608 ],\n",
              "       [0.4       , 0.4       , 0.28235295, ..., 0.20392157, 0.18039216,\n",
              "        0.1882353 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRJw6ykpCodp"
      },
      "source": [
        "#### Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2y3KyZgqCkti",
        "outputId": "bf383623-6ebf-4094-bcb3-dba85a5249d8"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "y_val = np.array(y_val)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "y_test = label_encoder.fit_transform(y_test)\n",
        "y_val = label_encoder.fit_transform(y_val)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz1L6L98CzHy"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "y_val = to_categorical(y_val)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZMy9f-m9imm"
      },
      "source": [
        "#### CREATING ARCHITECTURE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5J-vNoO5jQF"
      },
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import regularizers\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001), input_shape=(50 * 50,)))\n",
        "model.add(layers.Dense(5, activation='softmax'))"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_6t5g1b_sQg"
      },
      "source": [
        "model.compile(optimizer='rmsprop', \n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSzu-hkdAFCX"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGkPlZ7-AwPL",
        "outputId": "3297c39b-02e0-416a-eb41-44d94131207c"
      },
      "source": [
        "history = model.fit(x_train, y_train,epochs=75, validation_data =(x_val, y_val))\n",
        "\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "82/82 [==============================] - 2s 21ms/step - loss: 5.3674 - accuracy: 0.2264 - val_loss: 9.1248 - val_accuracy: 0.1516\n",
            "Epoch 2/75\n",
            "82/82 [==============================] - 2s 20ms/step - loss: 3.0430 - accuracy: 0.2444 - val_loss: 4.9653 - val_accuracy: 0.1690\n",
            "Epoch 3/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 2.6966 - accuracy: 0.2504 - val_loss: 4.6432 - val_accuracy: 0.2431\n",
            "Epoch 4/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 2.7334 - accuracy: 0.2366 - val_loss: 2.6426 - val_accuracy: 0.2106\n",
            "Epoch 5/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 2.4611 - accuracy: 0.2430 - val_loss: 3.9748 - val_accuracy: 0.2431\n",
            "Epoch 6/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 2.4896 - accuracy: 0.2418 - val_loss: 4.9807 - val_accuracy: 0.1667\n",
            "Epoch 7/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 2.5341 - accuracy: 0.2408 - val_loss: 6.2823 - val_accuracy: 0.1667\n",
            "Epoch 8/75\n",
            "82/82 [==============================] - 2s 20ms/step - loss: 2.4580 - accuracy: 0.2535 - val_loss: 5.8623 - val_accuracy: 0.2431\n",
            "Epoch 9/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 2.1952 - accuracy: 0.2755 - val_loss: 4.0049 - val_accuracy: 0.2431\n",
            "Epoch 10/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 2.2144 - accuracy: 0.2700 - val_loss: 6.9828 - val_accuracy: 0.1667\n",
            "Epoch 11/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 2.4165 - accuracy: 0.2637 - val_loss: 4.4327 - val_accuracy: 0.2431\n",
            "Epoch 12/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 2.1189 - accuracy: 0.2596 - val_loss: 3.2971 - val_accuracy: 0.1736\n",
            "Epoch 13/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.8883 - accuracy: 0.3163 - val_loss: 5.0278 - val_accuracy: 0.2431\n",
            "Epoch 14/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.9741 - accuracy: 0.2899 - val_loss: 5.5425 - val_accuracy: 0.1979\n",
            "Epoch 15/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 2.0806 - accuracy: 0.2574 - val_loss: 4.3380 - val_accuracy: 0.1725\n",
            "Epoch 16/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.9317 - accuracy: 0.2767 - val_loss: 4.4704 - val_accuracy: 0.1667\n",
            "Epoch 17/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 2.0323 - accuracy: 0.2518 - val_loss: 3.0233 - val_accuracy: 0.1887\n",
            "Epoch 18/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.7276 - accuracy: 0.3088 - val_loss: 1.7350 - val_accuracy: 0.2292\n",
            "Epoch 19/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.7418 - accuracy: 0.2621 - val_loss: 4.0767 - val_accuracy: 0.1667\n",
            "Epoch 20/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.8728 - accuracy: 0.2900 - val_loss: 3.1703 - val_accuracy: 0.2407\n",
            "Epoch 21/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.7698 - accuracy: 0.2964 - val_loss: 2.1231 - val_accuracy: 0.2523\n",
            "Epoch 22/75\n",
            "82/82 [==============================] - 2s 20ms/step - loss: 1.6855 - accuracy: 0.2944 - val_loss: 2.9769 - val_accuracy: 0.1933\n",
            "Epoch 23/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.7263 - accuracy: 0.3136 - val_loss: 3.5445 - val_accuracy: 0.1690\n",
            "Epoch 24/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.6923 - accuracy: 0.3109 - val_loss: 3.4743 - val_accuracy: 0.2407\n",
            "Epoch 25/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.6817 - accuracy: 0.3264 - val_loss: 3.3630 - val_accuracy: 0.1968\n",
            "Epoch 26/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.7512 - accuracy: 0.3143 - val_loss: 2.7980 - val_accuracy: 0.1933\n",
            "Epoch 27/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.7038 - accuracy: 0.3363 - val_loss: 3.1982 - val_accuracy: 0.2454\n",
            "Epoch 28/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.6891 - accuracy: 0.3310 - val_loss: 2.9329 - val_accuracy: 0.2419\n",
            "Epoch 29/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.5980 - accuracy: 0.3566 - val_loss: 2.2637 - val_accuracy: 0.2141\n",
            "Epoch 30/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.5755 - accuracy: 0.3354 - val_loss: 2.5784 - val_accuracy: 0.1991\n",
            "Epoch 31/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.6010 - accuracy: 0.3326 - val_loss: 1.8217 - val_accuracy: 0.2847\n",
            "Epoch 32/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.5298 - accuracy: 0.3530 - val_loss: 2.4774 - val_accuracy: 0.2130\n",
            "Epoch 33/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.5293 - accuracy: 0.3711 - val_loss: 1.9702 - val_accuracy: 0.2697\n",
            "Epoch 34/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.5107 - accuracy: 0.3694 - val_loss: 2.7066 - val_accuracy: 0.2118\n",
            "Epoch 35/75\n",
            "82/82 [==============================] - 2s 20ms/step - loss: 1.4923 - accuracy: 0.3830 - val_loss: 2.2531 - val_accuracy: 0.2350\n",
            "Epoch 36/75\n",
            "82/82 [==============================] - 2s 20ms/step - loss: 1.4796 - accuracy: 0.4070 - val_loss: 2.1757 - val_accuracy: 0.1968\n",
            "Epoch 37/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.5127 - accuracy: 0.3588 - val_loss: 2.4037 - val_accuracy: 0.2512\n",
            "Epoch 38/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.4749 - accuracy: 0.4088 - val_loss: 2.1336 - val_accuracy: 0.2697\n",
            "Epoch 39/75\n",
            "82/82 [==============================] - 2s 20ms/step - loss: 1.4389 - accuracy: 0.4109 - val_loss: 2.6012 - val_accuracy: 0.2604\n",
            "Epoch 40/75\n",
            "82/82 [==============================] - 2s 20ms/step - loss: 1.4900 - accuracy: 0.4020 - val_loss: 2.5720 - val_accuracy: 0.2627\n",
            "Epoch 41/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.4540 - accuracy: 0.4246 - val_loss: 1.8944 - val_accuracy: 0.3021\n",
            "Epoch 42/75\n",
            "82/82 [==============================] - 2s 20ms/step - loss: 1.3919 - accuracy: 0.4328 - val_loss: 1.9379 - val_accuracy: 0.2338\n",
            "Epoch 43/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.3742 - accuracy: 0.4548 - val_loss: 2.2820 - val_accuracy: 0.2002\n",
            "Epoch 44/75\n",
            "82/82 [==============================] - 2s 20ms/step - loss: 1.4225 - accuracy: 0.4353 - val_loss: 2.0241 - val_accuracy: 0.2859\n",
            "Epoch 45/75\n",
            "82/82 [==============================] - 2s 20ms/step - loss: 1.3973 - accuracy: 0.4371 - val_loss: 1.8470 - val_accuracy: 0.2917\n",
            "Epoch 46/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.3602 - accuracy: 0.4554 - val_loss: 2.0685 - val_accuracy: 0.2477\n",
            "Epoch 47/75\n",
            "82/82 [==============================] - 2s 20ms/step - loss: 1.3478 - accuracy: 0.4620 - val_loss: 1.8288 - val_accuracy: 0.2998\n",
            "Epoch 48/75\n",
            "82/82 [==============================] - 2s 20ms/step - loss: 1.3072 - accuracy: 0.4642 - val_loss: 1.9851 - val_accuracy: 0.2766\n",
            "Epoch 49/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.3486 - accuracy: 0.4846 - val_loss: 1.9971 - val_accuracy: 0.2743\n",
            "Epoch 50/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.3720 - accuracy: 0.4758 - val_loss: 1.9827 - val_accuracy: 0.3009\n",
            "Epoch 51/75\n",
            "82/82 [==============================] - 2s 20ms/step - loss: 1.3331 - accuracy: 0.4706 - val_loss: 2.3399 - val_accuracy: 0.2292\n",
            "Epoch 52/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.3136 - accuracy: 0.4918 - val_loss: 2.6562 - val_accuracy: 0.2569\n",
            "Epoch 53/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.3407 - accuracy: 0.4781 - val_loss: 2.2073 - val_accuracy: 0.2894\n",
            "Epoch 54/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.3041 - accuracy: 0.4992 - val_loss: 2.4079 - val_accuracy: 0.2153\n",
            "Epoch 55/75\n",
            "82/82 [==============================] - 2s 20ms/step - loss: 1.3111 - accuracy: 0.5102 - val_loss: 2.5466 - val_accuracy: 0.2674\n",
            "Epoch 56/75\n",
            "82/82 [==============================] - 2s 20ms/step - loss: 1.3470 - accuracy: 0.4892 - val_loss: 2.2059 - val_accuracy: 0.2523\n",
            "Epoch 57/75\n",
            "82/82 [==============================] - 2s 20ms/step - loss: 1.2515 - accuracy: 0.5229 - val_loss: 1.8381 - val_accuracy: 0.2731\n",
            "Epoch 58/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.2566 - accuracy: 0.5182 - val_loss: 1.8442 - val_accuracy: 0.3275\n",
            "Epoch 59/75\n",
            "82/82 [==============================] - 2s 20ms/step - loss: 1.2446 - accuracy: 0.5262 - val_loss: 2.0018 - val_accuracy: 0.2743\n",
            "Epoch 60/75\n",
            "82/82 [==============================] - 2s 20ms/step - loss: 1.2734 - accuracy: 0.5203 - val_loss: 2.3791 - val_accuracy: 0.2801\n",
            "Epoch 61/75\n",
            "82/82 [==============================] - 2s 20ms/step - loss: 1.2517 - accuracy: 0.5383 - val_loss: 1.9574 - val_accuracy: 0.2882\n",
            "Epoch 62/75\n",
            "82/82 [==============================] - 2s 20ms/step - loss: 1.2112 - accuracy: 0.5505 - val_loss: 2.1181 - val_accuracy: 0.2674\n",
            "Epoch 63/75\n",
            "82/82 [==============================] - 2s 20ms/step - loss: 1.2874 - accuracy: 0.5251 - val_loss: 2.8316 - val_accuracy: 0.2523\n",
            "Epoch 64/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.2252 - accuracy: 0.5605 - val_loss: 2.2898 - val_accuracy: 0.2569\n",
            "Epoch 65/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.2061 - accuracy: 0.5632 - val_loss: 2.3765 - val_accuracy: 0.2951\n",
            "Epoch 66/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.2810 - accuracy: 0.5603 - val_loss: 2.1786 - val_accuracy: 0.3102\n",
            "Epoch 67/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.1926 - accuracy: 0.5803 - val_loss: 2.1466 - val_accuracy: 0.2940\n",
            "Epoch 68/75\n",
            "82/82 [==============================] - 2s 20ms/step - loss: 1.2079 - accuracy: 0.5559 - val_loss: 2.1366 - val_accuracy: 0.3079\n",
            "Epoch 69/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.1827 - accuracy: 0.5699 - val_loss: 2.0868 - val_accuracy: 0.2870\n",
            "Epoch 70/75\n",
            "82/82 [==============================] - 2s 20ms/step - loss: 1.2044 - accuracy: 0.5770 - val_loss: 2.4123 - val_accuracy: 0.2361\n",
            "Epoch 71/75\n",
            "82/82 [==============================] - 2s 20ms/step - loss: 1.2160 - accuracy: 0.5538 - val_loss: 2.1632 - val_accuracy: 0.2778\n",
            "Epoch 72/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.1690 - accuracy: 0.5707 - val_loss: 2.6430 - val_accuracy: 0.2766\n",
            "Epoch 73/75\n",
            "82/82 [==============================] - 2s 20ms/step - loss: 1.2347 - accuracy: 0.5724 - val_loss: 2.5350 - val_accuracy: 0.2500\n",
            "Epoch 74/75\n",
            "82/82 [==============================] - 2s 20ms/step - loss: 1.1910 - accuracy: 0.5803 - val_loss: 1.9772 - val_accuracy: 0.2940\n",
            "Epoch 75/75\n",
            "82/82 [==============================] - 2s 19ms/step - loss: 1.1393 - accuracy: 0.5871 - val_loss: 2.3813 - val_accuracy: 0.2720\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXK4vgsxRaGb"
      },
      "source": [
        "### Evaluation on Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdDCiEHM_wWR",
        "outputId": "543798c3-d17b-4a54-c0cc-1a4b015d47cf"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('test_acc:', test_acc)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28/28 [==============================] - 0s 6ms/step - loss: 2.2991 - accuracy: 0.2679\n",
            "test_acc: 0.2678983807563782\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SbYCppgRgkL"
      },
      "source": [
        "### Prdiction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1MbNaVYGEpi",
        "outputId": "476045f0-4a28-416a-ab1a-05b3e883e999"
      },
      "source": [
        "pred = model.predict(x_test[0:1])\n",
        "pred"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.08465333, 0.78229356, 0.09792668, 0.0034993 , 0.03162714]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6mSsiQORIIj"
      },
      "source": [
        "###Note: \n",
        "##### Applied Drop Out and Regularization one-by-one, but validation accuracy did not improve."
      ]
    }
  ]
}